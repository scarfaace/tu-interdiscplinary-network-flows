{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.random.set_seed(123)\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe():\n",
    "    df = pd.read_csv(\"10percent_cut.tsv\", sep='\\t')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(df):\n",
    "    train, test = train_test_split(df[['transcription', 'label']], train_size=0.7, random_state=123)\n",
    "\n",
    "    train_texts = train['transcription'].values\n",
    "    train_label = train['label'].values\n",
    "\n",
    "    validation_texts = test['transcription'].values\n",
    "    validation_label = test['label'].values\n",
    "\n",
    "#     train_texts = remove_float_instances(train_texts_tmp)\n",
    "#     validation_texts = remove_float_instances(validation_texts_tmp)\n",
    "\n",
    "    return train_texts, train_label, validation_texts, validation_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_graphs(history, metric):\n",
    "  plt.plot(history.history[metric])\n",
    "  plt.plot(history.history['val_'+metric], '')\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(metric)\n",
    "  plt.legend([metric, 'val_'+metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_alphabet(dataframe):\n",
    "    category_lines = {1: [], 0: []}\n",
    "    all_categories = [0, 1]\n",
    "    alphabet = set()\n",
    "\n",
    "    for index, row in dataframe.iterrows():\n",
    "        ascii_transcription = row['transcription']\n",
    "        tokenized_transcription = [char for char in ascii_transcription]\n",
    "        for token in tokenized_transcription:\n",
    "            alphabet.add(token)\n",
    "\n",
    "        category_lines[row['label']].append(ascii_transcription)\n",
    "\n",
    "    N_LETTERS = len(alphabet)\n",
    "    ALL_LETTERS = ''.join(alphabet)\n",
    "    return N_LETTERS, ALL_LETTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_to_embeddings(tokenizer, train_texts, validation_texts):\n",
    "    sequences = tokenizer.texts_to_sequences(train_texts)\n",
    "    validation_sequences = tokenizer.texts_to_sequences(validation_texts)\n",
    "    # print(train_texts[0])\n",
    "    # print(sequences[0])\n",
    "    data = pad_sequences(sequences, maxlen=750, padding='post')\n",
    "    validation_data = pad_sequences(validation_sequences, maxlen=750, padding='post')\n",
    "    return data, validation_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(input_dimension, learning_rate):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(\n",
    "            input_dim=input_dimension,\n",
    "            output_dim=128),\n",
    "        tf.keras.layers.LSTM(128),\n",
    "        #tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        #tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    # %%\n",
    "    # model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    #               optimizer=tf.keras.optimizers.Adam(1),\n",
    "    #               metrics=['}accuracy'])\n",
    "\n",
    "    # opt = SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate), metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.3 s, sys: 376 ms, total: 30.7 s\n",
      "Wall time: 30.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = get_dataframe()\n",
    "train_texts, train_label, validation_texts, validation_label = load_dataset(df)\n",
    "tokenizer = Tokenizer(num_words=None, char_level=True, oov_token='UNK', lower=False)\n",
    "tokenizer.fit_on_texts(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'R': 1, 't': 2, ';': 3, '$': 4, '&': 5, '\\t': 6, 'w': 7, '(': 8, 'm': 9, '1': 10, '5': 11, '!': 12, '_': 13, '@': 14, ',': 15, 'Z': 16, 'v': 17, 'p': 18, '0': 19, 'X': 20, '+': 21, 'B': 22, '7': 23, 'W': 24, '9': 25, '#': 26, 'D': 27, 'Y': 28, ':': 29, ' ': 30, '\\n': 31, '*': 32, 'Q': 33, 'd': 34, 'a': 35, '2': 36, 'n': 37, 'f': 38, 'b': 39, '[': 40, '`': 41, 'U': 42, '3': 43, '4': 44, 'I': 45, \"'\": 46, 'l': 47, 'e': 48, 'r': 49, ')': 50, 'o': 51, '^': 52, 'T': 53, '%': 54, '/': 55, '\"': 56, 'N': 57, '-': 58, 'V': 59, ']': 60, 'A': 61, 's': 62, '\\\\': 63, '.': 64, 'x': 65, 'c': 66, '6': 67, '8': 68, 'P': 69, 'S': 70, '?': 71, 'i': 72}\n"
     ]
    }
   ],
   "source": [
    "N_LETTERS, ALL_LETTERS = create_alphabet(df)\n",
    "char_dict = {}\n",
    "for i, char in enumerate(ALL_LETTERS):\n",
    "    char_dict[char] = i + 1\n",
    "print(char_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 µs, sys: 0 ns, total: 8 µs\n",
      "Wall time: 12.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer.word_index = char_dict\n",
    "tokenizer.word_index[tokenizer.oov_token] = max(char_dict.values()) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.8 s, sys: 988 ms, total: 44.8 s\n",
      "Wall time: 44.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data, validation_data = sequence_to_embeddings(tokenizer=tokenizer, train_texts=train_texts,\n",
    "                                           validation_texts=validation_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-loop version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dimension = len(char_dict.values())\n",
    "model = define_model(input_dimension=input_dimension, learning_rate=0.001)\n",
    "class_weights = dict(zip(np.unique(train_label), class_weight.compute_class_weight('balanced', np.unique(train_label), train_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 35s 375ms/step - loss: 0.0000e+00 - accuracy: 0.0842\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=data, y=train_label, epochs=1, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 5s 114ms/step - loss: 0.0000e+00 - accuracy: 0.0738\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x=validation_data, y=validation_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[   0 1129]\n",
      " [   0   90]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_classes(x=validation_data)\n",
    "confusion = tf.math.confusion_matrix(labels=validation_label, predictions=predictions, num_classes=2)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-f0080dad1663>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplot_graphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplot_graphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-c2b265b8e833>\u001b[0m in \u001b[0;36mplot_graphs\u001b[0;34m(history, metric)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_graphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epochs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val_accuracy'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(1,2,1)\n",
    "plot_graphs(history, 'accuracy')\n",
    "plt.subplot(1,2,2)\n",
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop version for finding best learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = np.linspace(0.00001, 0.00000001, 20) #[1, 0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001]\n",
    "accuracies = []\n",
    "confusion_matrices = []\n",
    "tf.random.set_seed(123)\n",
    "np.random.seed(7)\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    input_dimension = len(char_dict.values())\n",
    "    model = define_model(input_dimension=input_dimension, learning_rate=learning_rate)\n",
    "    class_weights = dict(zip(np.unique(train_label), class_weight.compute_class_weight('balanced', np.unique(train_label), train_label)))\n",
    "\n",
    "    history = model.fit(x=data, y=train_label, epochs=5, class_weight=class_weights)\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(x=validation_data, y=validation_label)\n",
    "\n",
    "    predictions = model.predict_classes(x=validation_data)\n",
    "    confusion = tf.math.confusion_matrix(labels=validation_label, predictions=predictions, num_classes=2)\n",
    "    \n",
    "    print(confusion)\n",
    "    \n",
    "    accuracies.append(test_acc)\n",
    "    confusion_matrices.append(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy saving & loading preprocessed arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving data & validation data to prevent preprocessing\n",
    "#np.savetxt('validation_numpy.txt', validation_data, fmt='%d')\n",
    "#np.savetxt('data_numpy.txt', data, fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('data_numpy.txt', dtype=int)\n",
    "validation_data = np.loadtxt('validation_numpy.txt', dtype=int)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
